{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victorjoseij/deeplearning/blob/main/2348570_DLlab5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0jLHfNbn5PE"
      },
      "source": [
        "Convolutional Neural Network model to classify animals images into their respective species"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2gH8z0-n5PK",
        "outputId": "25034896-c768-4026-ce78-3ef172afd2dd"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'cv2'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2T4tJiBn5PO"
      },
      "source": [
        "\n",
        "Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDDLmaxAn5PP",
        "outputId": "287cabf0-e0ae-416b-86e9-dd1858e8941f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Skipping tensorflow as it is not installed.\n"
          ]
        }
      ],
      "source": [
        "# Defining constants\n",
        "\n",
        "data_dir = \"E:\\datasets\\raw-img\"\n",
        "img_size = (224, 224)  # Size of the images\n",
        "batch_size = 32  # Batch size for data generators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZFnYAJrn5PQ"
      },
      "outputs": [],
      "source": [
        "# Initializing ImageDataGenerator for data augmentation and normalization\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,  # Normalizing pixel values to [0, 1]\n",
        "    validation_split=0.1,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,  # Applying shear transformation with 20% intensity\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True  # Randomly flipping images horizontally\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLFQtdoKn5PR"
      },
      "source": [
        "Creating data generators for training and validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pyc81rrcn5PR"
      },
      "outputs": [],
      "source": [
        "train_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',  # Using training subset\n",
        "    seed=42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ju2NhFzPn5PS"
      },
      "outputs": [],
      "source": [
        "validation_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',  # Using validation subset\n",
        "    seed=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vu0ADLG2n5PT"
      },
      "outputs": [],
      "source": [
        "num_classes = len(train_generator.class_indices)\n",
        "print(\"Class indices:\", train_generator.class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAXYuXTkn5PT"
      },
      "outputs": [],
      "source": [
        "# Calculating number of steps per epoch for training and validation\n",
        "steps_per_epoch_train = train_generator.samples // batch_size\n",
        "steps_per_epoch_validation = validation_generator.samples // batch_size\n",
        "\n",
        "print(steps_per_epoch_train)\n",
        "print(steps_per_epoch_validation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7t8Xooin5PU"
      },
      "source": [
        "Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaDVOtP_n5PU"
      },
      "outputs": [],
      "source": [
        "# Defining the CNN model\n",
        "model = Sequential()\n",
        "\n",
        "# Convolutional layers with batch normalization and ReLU activation\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euBFGuq9n5PV"
      },
      "outputs": [],
      "source": [
        "# Flattening layer to transition from convolutional layers to fully connected layers\n",
        "model.add(Flatten())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkPo3kc3n5PV"
      },
      "outputs": [],
      "source": [
        "# Fully connected layers\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Output layer with softmax activation for multi-class classification\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) # Using adam optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5nUl_WUn5PW"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuzlVRoqn5PW"
      },
      "outputs": [],
      "source": [
        "epochs = 20\n",
        "\n",
        "# Training the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=len(validation_generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJiSnZnan5PW"
      },
      "source": [
        "Inference\n",
        "After each epoch the model's training loss is getting decreased while the accuracy is increasing. This is a good sign. It took 736 steps per epoch for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pg3X4S0pn5PW"
      },
      "outputs": [],
      "source": [
        "# Evaluating the trained model\n",
        "loss, accuracy = model.evaluate(validation_generator, steps=len(validation_generator))\n",
        "print(\"Validation Loss:\", loss)\n",
        "print(\"Validation Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qq5tjPtJn5PX"
      },
      "outputs": [],
      "source": [
        "Inference\n",
        "Validation accuracy is approximately 57.92%.\n",
        "Validation loss is approximately 1.3318.\n",
        "A high validation accuracy and low validation loss indicate that the model is generalizing well to the validation dataset. It took 82 batches for validation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgKFURFmn5PX"
      },
      "outputs": [],
      "source": [
        "Visualizing training and validation (accuracy and loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTO3CEvkn5PX"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHLoCn4-n5PX"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PI0zls19n5PY"
      },
      "source": [
        "Inference\n",
        "By this way we can visualize the model's training and validation (accuracy & loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsgz5ClRn5PY"
      },
      "source": [
        "Conclusion\n",
        "Thus the task to build a convolutional neural network model to classify the animal images based on species has been implemented successfully.\n",
        "While training the model it took 736 steps per epochs, and it gave a good result. The accuracy is increased while the loss is decreased.\n",
        "For validation it took 82 steps per epochs. Obtained high validation acccuracy and low validation loss shows that the model is working fine. We can use this model in realtime to classify the images."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}